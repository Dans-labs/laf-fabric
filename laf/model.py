import os
import collections
import array
from .lib import grouper
from .settings import Names

def arrayify(source_list):
    '''Efficient storage of a list of lists of integers in two Python :py:mod:`array`.

    *This is one of the most important tricks of the LAF-Fabric, and yet it is only 10 lines of code!*

    Args:
        source_list (iterable):
            a list of lists of integers
    
    Returns:
        (index_array, items_array):
            two :py:mod:`array` s.

        *index_array* contains an index for each item in *source_list*.
        *items_array* contains all the items in the following way: if an item with *n* members has to be added,
        then first the number *n* is added, and then all the members.
        This is how you get the original information back: if you want the 
        members of item *i* in *source_list*, read number *i* in *index_array*, say *k*, go to position *k* in
        *items_array*, read the number at that position, say *n*,
        and then find the members at the next *n* positions in *items_array*.

    '''
    dest_array = array.array('I')
    dests_array = array.array('I')
    j = 0

    for i in range(len(source_list)):
        items = source_list[i]
        dest_array.append(j)
        dests_array.append(len(items))
        dests_array.extend(items)
        j += 1 + len(items)
    return (dest_array, dests_array)

def make_inverse(mapping):
    '''Creates the inverse lookup table for a data table given as a dictionary.

    This is a low level function for creating inverse mappings.
    When mappings (such as from xml-ids to integers vv.) are stored to disk, the inverse mapping is not stored.
    Upon loading, the inverse mapping is generated by means of this function.
    '''
    return dict([(y,x) for (x,y) in mapping.items()])

def make_array_inverse(arraylist):
    '''Creates the inverse lookup table for a data table given as a Python array.

    This is a low level function for creating inverse mappings.
    When mappings (such as from xml-ids to integers vv.) are stored to disk, the inverse mapping is not stored.
    Upon loading, the inverse mapping is generated by means of this function.
    '''
    return dict([(x,n) for (n,x) in enumerate(arraylist)])

def normalize_ranges(ranges):
    '''Normalizes a set of ranges.

    Ranges come from the regions in the primary data.
    The anchors in the regions point to positions between characters in the primary data.
    So range (1,1) points to the point after the first character and before the second one.
    This range does not include any character. But the range (0,1) correspondes with the interval
    between the points before any character and the point after the first character.
    So this is character [0] in the string.
    
    Nodes may be linked to multiple regions. Then we get multiple ranges associated to nodes.
    This function simplifies a set of ranges: overlapping ranges will be joined, adjacent regions
    will be combined, ranges will be ordered.

    Args:
        ranges(iterable of 2-tuples):
            List of ranges, where every range is a tuple of exactly 2 integers.

    Returns:
        The result is a plain list of integers. The number of integers is even.
        The first two correspond to the first range, the second two to the second range and so on.
        This way we can deliver the results of many nodes as a compact *double_array*.
    '''
    covered = {}
    for (start, end) in ranges:
        if start == end:
            if start not in covered:
                covered[start] = False
        else:
            for i in range(start, end):
                covered[i] = True
    cur_start = None
    cur_end = None
    result = []
    for i in sorted(covered.keys()):
        if not covered[i]:
            if cur_end != None:
                result.extend((cur_start, cur_end))
            result.extend((i, i))
            cur_start = None
            cur_end = None
        elif cur_end == None or i > cur_end:
            if cur_end != None:
                result.extend((cur_start, cur_end))
            cur_start = i
            cur_end = i + 1
        else:
            cur_end = i + 1
    if cur_end != None:
        result.extend((cur_start, cur_end))

    return result

def model(data, data_items, stamp):
    '''Remodels various data structures

    Args:
        data_items:
            data structures coming from :mod:`parse <laf.parse>`

        stamp (:class:`Timestamp <laf.timestamp.Timestamp>`):
            object for issuing progress messages

    Returns:
        The resulting remodelled data structures.

    The transformations are:

    Nodes and regions:
        The list linking regions to nodes is transformed into a double array.

    Nodes and anchors:
        As a preparation to sorting, the minimal and maximal anchors of each node
        are determined. Nodes may be linked to many regions.

        It also creates a list of node events:

        For each anchor position, a list will be created of nodes that start, terminate, suspend and resume there.
        
        * A node *starts* at an anchor if the anchor is the first anchor position of that node
        * A node *terminates* at an anchor if the anchor is the last anchor position of that node
        * A node *suspends* at an anchor position if
            #. the anchor position belongs to that node, 
            #. the next anchor position does not belong to that node
            #. there are later anchor positions that belong to that node
        * A node *resumes* at an anchor position if
            #. the anchor position belongs to that node, 
            #. the previous anchor position does not belong to that node
            #. there are earlier anchor positions that belong to that node

    Node sorting:
        Create a list of nodes in a sort order derived from their linking to regions,
        and the ordered nature of the primary data. 

        *node1* comes before *node2* if *node1* starts before *node2*.
        If *node1* and *node2* start at the same point, the object that ends last comes first.
        Otherwise objects count as equal in position.
        If the objects are sorted in this way, embedding objects come before all objects that are embedded in it.

    Nodes and edges:
        Collect the outgoing and incoming edges for each node in a pair of double arrays.

        Collect the set of unannotated edges.

    '''
    result_items = []

    def deliver(dkey, item, mod_data):
        data_items["{}{}".format(dkey, item)] = mod_data
        result_items.append((dkey, item))

    def model_x():
        stamp.progress("XML-IDS (inverse mapping)")
        for item in ('node', 'edge'):
            deliver("X_rep_", item, make_inverse(data_items['X_int_{}'.format(item)]))

    def model_regions():
        stamp.progress("NODES AND REGIONS")

        node_region_list = data_items["node_region_list"]
        n_node = len(node_region_list)

        stamp.progress("NODES ANCHOR BOUNDARIES")

#   in node_anchor_min/max the value 0 counts as undefined.
#   So we have to increase all real values by one in order to make the distinction.

        node_anchor_min = array.array('I', [0 for i in range(n_node)])
        node_anchor_max = array.array('I', [0 for i in range(n_node)])
        node_linked = array.array('I')
        region_begin = data_items["region_begin"]
        region_end = data_items["region_end"]

        node_anchor_list = []
        for node in range(n_node):
            links = node_region_list[node]
            if len(links) == 0:
                node_anchor_list.append([])
                continue
            node_linked.append(node)
            ranges = []
            for r in links:
                this_anchor_begin = region_begin[r]
                this_anchor_end = region_end[r]
                ranges.append((this_anchor_begin, this_anchor_end))
            norm_ranges = normalize_ranges(ranges)
            node_anchor_list.append(norm_ranges)

#       we store the true value increased by one
            node_anchor_min[node] = min(norm_ranges) + 1
            node_anchor_max[node] = max(norm_ranges) + 1

        (node_anchor, node_anchor_items) = arrayify(node_anchor_list)
        deliver("node_anchor_min", '', node_anchor_min))
        deliver("node_anchor_max", '', node_anchor_max))
        deliver("node_anchor", '', node_anchor))
        deliver("node_anchor_items", '', node_anchor_items))
        node_region_list = None
        del data_items["node_region_list"]

        def interval(node):
            ''' Key function used when sorting objects according to embedding and left right.

            Args:
                node (int):
                    interval

            Returns:
                a tuple containing the left boundary and the nagative of the right boundary
            '''
            return (node_anchor_min[node], -node_anchor_max[node])

        stamp.progress("NODES SORTING BY REGIONS")

        node_sort = array.array('I', sorted(node_linked, key=interval))
        deliver("node_sort", '', node_sort))
        deliver("node_sort_inv", '', make_array_inverse(data_items['node_sort']))

        stamp.progress("NODES EVENTS")

        anchor_max = max(node_anchor_max) - 1
        node_events = list([([],[],[]) for n in range(anchor_max + 1)])

        for n in node_sort:
            ranges = node_anchor_list[n]
            amin = ranges[0]
            amax = ranges[len(ranges)-1] 
            for (r, (a_start, a_end)) in enumerate(grouper(ranges, 2)):
                is_first = r == 0
                is_last = r == (len(ranges) / 2) - 1
                start_kind = 0 if is_first else 1 # 0 = start,   1 = resume
                end_kind = 3 if is_last else 2    # 2 = suspend, 3 = end
                if amin == amax:
                    node_events[a_start][1].extend([(n, 0), (n,3)])
                else:
                    node_events[a_start][0].append((n, start_kind))
                    node_events[a_end][2].append((n, end_kind))

        node_events_n = array.array('I')
        node_events_k = array.array('I')
        node_events_a = list([[] for a in range(anchor_max + 1)])

        e_index = 0
        for (anchor, events) in enumerate(node_events):
            events[2].reverse()
            for main_kind in (2, 1, 0):
                for (node, kind) in events[main_kind]:
                    node_events_n.append(node)
                    node_events_k.append(kind)
                    node_events_a[anchor].append(e_index)
                    e_index += 1

        node_events = None
        (node_events, node_events_items) = arrayify(node_events_a)
        node_events_a = None

        deliver("node_events_n", '', node_events_n))
        deliver("node_events_k", '', node_events_k))
        deliver("node_events", '', node_events))
        deliver("node_events_items", '', node_events_items))

        node_anchor_list = None

    def model_conn():
        stamp.progress("CONNECTIVITY")

        edges_from = data_items["edges_from"]
        edges_to = data_items["edges_to"]
        labeled_edges = set()
        efeatures = {'main': set(), 'annox': set()}
        connection_key = Names.comp(('C', data, False), ())
        connectioni_key = Names.comp(('C', data, True), ())

        for dkey in data_items:
            (d, start, end, comps) = Names.decomp(dkey)
            if d != 'F': continue
            (feature, kind, data) = comps
            if kind != 'edge': continue
            efeatures[kind][data].add(dkey)

        for feature_key in efeatures[data]:
            feature_map = data_items[feature_key]

            connections = collections.defaultdict(lambda: set())
            connectionsi = collections.defaultdict(lambda: set())
            for (edge, fvalue) in feature_map.items():
                labeled_edges.add(edge)
                node_from = edges_from[edge]
                node_to = edges_to[edge]
                connections[feature_key][node_from].add((node_to, fvalue))
                connectionsi[feature_key][node_to].add((node_from, fvalue))
            deliver(connection_key, feature, connections)
            deliver(connectioni_key, feature, connectionsi)

        connections = {}
        connectionsi = {}
        if data == 'main':
            for edge in range(len(edges_from)):
                if edge in labeled_edges:
                    continue
                node_from = edges_from[edge]
                node_to = edges_to[edge]
                connections[node_from].add((node_to, ''))
                connectionsi[node_to].add((node_from, ''))
            deliver(connection_key, ('','','-','edge'), connections)
            deliver(connectioni_key, ('','','-','edge'), connectionsi)
        elif data == 'annox':
            for edge in range(len(edges_from)):
                if edge in labeled_edges:
                    node_from = edges_from[edge]
                    node_to = edges_to[edge]
                    connections[node_from].add((node_to, ''))
                    connectionsi[node_to].add((node_from, ''))
            deliver(connection_key, ('','','+','edge'), connections)
            deliver(connectioni_key, ('','','+','edge'), connectionsi)

    if data == 'main':
        model_x()
        model_regions()
    model_conn()

    return result_items

