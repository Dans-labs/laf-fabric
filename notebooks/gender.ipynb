{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Gender"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This tasks extracts a table from the Hebrew Bible data. Each row specifies a chapter and has the percentage of masculine and feminine words is that chapter."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1. Importing\n",
      "The next cell loads the required libraries and creates a task processor.\n",
      "\n",
      "Note the *matplotlib*, this is the one that can draw a chart based on a table.\n",
      "In order to show the chart withib this page, we issue a magic command (%matplotlib inline).\n",
      "\n",
      "The Notebook class in *graf.notebook* implements a LAF-Fabric task processor."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import collections\n",
      "import matplotlib.pyplot as plt\n",
      "import graf\n",
      "from graf.notebook import Notebook\n",
      "%matplotlib inline\n",
      "processor = Notebook()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2. Loading\n",
      "\n",
      "The processor needs data. Here is where we say what data to load. We do not need the XML identifiers as they show up in the original LAF resource. But we do need a few features of nodes, namely the ones that give us the gender of the words, and the numbers of the chapters and the books in which the chapters are contained.\n",
      "\n",
      "The *init* function actually draws that data in, and it will take a few seconds. It needs to know the name of the LAF header file (in fact the *GrAF* header file).\n",
      "The '--' means that we do not draw in an extra annotation package. If you want to do that, this is the place to give the name of such a package.\n",
      "\n",
      "Then *gender* is just a name we choose to give to this task. This name determines where on the filesystem the log file and output (if any) will be put."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processor.init('bhs3.txt.hdr', '--', 'gender', {\n",
      "    \"xmlids\": {\n",
      "        \"node\": False,\n",
      "        \"edge\": False,\n",
      "    },\n",
      "    \"features\": {\n",
      "        \"shebanq\": {\n",
      "            \"node\": [\n",
      "                \"db.otype\",\n",
      "                \"ft.gender\",\n",
      "                \"sft.chapter,book\",\n",
      "            ],\n",
      "            \"edge\": [\n",
      "            ],\n",
      "        },\n",
      "    },\n",
      "})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 3. Naming\n",
      "\n",
      "The workbench provides us with some objects by which we can query for data. Here they are:\n",
      "\n",
      "### F\n",
      "All that you want to know about features and are not afraid to ask.\n",
      "It is an object, and for each feature that you have declared, it has a member\n",
      "with a handy name. For example, ``F.shebanq_db_otype`` is a feature object\n",
      "that corresponds with the LAF feature given in an annotation in the annotation space ``shebanq``,\n",
      "with label ``db`` and name ``otype``.\n",
      "It is a node feature, because otherwise the name had a \n",
      "``_e`` appended to it.\n",
      "You can look up a feature value of this feature, say for node ``n``,by saying:\n",
      "``F.shebanq_db_otype.v(n)``. \n",
      "\n",
      "### P(node)\n",
      "Your gateway to the primary data. For nodes *n* that are linked to the primary data by one or more regions,\n",
      "P(*n*) yields a set of chunks of primary data, corresponding with those regions.\n",
      "The chunks are maximal, non-overlapping, ordered according to the primary data.\n",
      "Every chunk is given as a tuple (*pos*, *text*), where *pos* is the position in the primary data where\n",
      "the start of *text* can be found, and *text* is the chunk of actual text that is specified by the region.\n",
      "The primary data is only available if you have specified in the *load* directives: \n",
      "``primary: True``\n",
      "\n",
      "### NN(test=function value=something)\n",
      "If you want to walk through all the nodes, possibly skipping some, then this is your method.\n",
      "It is an *iterator* that yields a new node everytime it is called.\n",
      "The order is so-called *primary data order*, which will be explained below.\n",
      "The ``test`` and ``value`` arguments are optional.\n",
      "If given, ``test`` should be a *callable* with one argument, returning a string;\n",
      "``value`` should be a string.\n",
      "``test`` will be called for each passing node,\n",
      "and if the value returned is not equal to the given ``value``,\n",
      "the node will be skipped.\n",
      "\n",
      "### X\n",
      "If you need to convert the integers that identify nodes and edges in the compiled data back to\n",
      "their original XML identifiers, you can do that with the *X* object.\n",
      "It has two members, ``X.node`` and ``X.edge``, which contain the separate mapping tables for\n",
      "nodes and edges. Both have two methods, corresponding to the direction of the translation:\n",
      "with ``X.node.i(\u00abxml id\u00bb)`` you get the corresponding number of a node, and with ``X.node.r(\u00abnumber\u00bb)``\n",
      "you get the original XML id by which the node was identified in the LAF resource."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(msg, P, NN, F, X) = processor.data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 4. Task Execution\n",
      "\n",
      "### Initialization\n",
      "\n",
      "We initialize the counters in which we store the word counts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stats = [0, 0, 0]\n",
      "cur_chapter = None\n",
      "ch = []\n",
      "m = []\n",
      "f = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Looping\n",
      "\n",
      "Here we loop over a bunch of nodes (in fact over all nodes), in a convenient document order.\n",
      "We keep track of the chapter we are in and accumulate counts of the words, masculine and feminine.\n",
      "For each chapter we create entries in the *ch*, *m* and *f* lists.\n",
      "\n",
      "Note also the progress messages after each chapter."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for node in NN():\n",
      "    otype = F.shebanq_db_otype.v(node)\n",
      "    if otype == \"word\":\n",
      "        stats[0] += 1\n",
      "        if F.shebanq_ft_gender.v(node) == \"masculine\":\n",
      "            stats[1] += 1\n",
      "        elif F.shebanq_ft_gender.v(node) == \"feminine\":\n",
      "            stats[2] += 1\n",
      "    elif otype == \"chapter\":\n",
      "        if cur_chapter != None:\n",
      "            masc = 0 if not stats[0] else 100 * float(stats[1]) / stats[0]\n",
      "            fem = 0 if not stats[0] else 100 * float(stats[2]) / stats[0]\n",
      "            ch.append(cur_chapter)\n",
      "            m.append(masc)\n",
      "            f.append(fem)\n",
      "        this_chapter = \"{} {}\".format(F.shebanq_sft_book.v(node), F.shebanq_sft_chapter.v(node))\n",
      "        sys.stderr.write(\"\\r{:<15}\".format(this_chapter))\n",
      "        stats = [0, 0, 0]\n",
      "        cur_chapter = this_chapter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 5 Closing\n",
      "\n",
      "We need to close open files."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processor.final()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 6 Showing off\n",
      "\n",
      "Everything is still in memory. Now it is the time to generate a graphical representation of the data.\n",
      "The *matplotlib* is full of instruments to do that, here we just show a line graph of 20 chapters.\n",
      "\n",
      "If you want to see another series of chapters, just modify the *start* and *end* variables below and execute again by pressing *Shift Enter*. You can repeat this as often as you like without re-running earlier steps."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = range(len(ch))\n",
      "start = 500\n",
      "end = 520\n",
      "plt.plot(x[start:end], m[start:end], 'b-', x[start:end], f[start:end], 'r-')\n",
      "plt.axis([start, end, 0, 100])\n",
      "plt.xticks(x[start:end], ch[start:end], rotation='vertical')\n",
      "plt.margins(0.2)\n",
      "plt.subplots_adjust(bottom=0.15);\n",
      "plt.title('gender');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}