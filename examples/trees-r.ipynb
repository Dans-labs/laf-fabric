{
 "metadata": {
  "name": "",
  "signature": "sha256:f8bc01bb9640a6c01dec2ae6be827be39954bb155c2367bb8e3e6f418aa8ba05"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
      "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"left\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
      "<a href=\"http://tla.mpi.nl\" target=\"_blank\"><img align=\"right\" src=\"images/TLA-xsmall.png\"/></a>\n",
      "<a href=\"http://www.dans.knaw.nl\" target=\"_blank\"><img align=\"right\"src=\"images/DANS-xsmall.png\"/></a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Trees - the rough path"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We show the embedding of nodes annotated as sentences, clauses, phrases, subphrases and words.\n",
      "We put them in a format (eventually) such that they can be read by TQUERY.\n",
      "Then Rens Bod and Andreas van Cranenburgh can do interesting business with it.\n",
      "\n",
      "The approach chosen in this notebook turns out to have problems.\n",
      "\n",
      "Method\n",
      "======\n",
      "We walk through all anchor positions of the primary data, and follow the node events at that position.\n",
      "LAF-Fabric tries hard to generate node events in an order that respects the factual embedding of nodes.\n",
      "\n",
      "However, some nodes have gaps, some nodes are linked to regions with zero length, and some nodes have identical regions. \n",
      "Moreover, the way our current LAF resource of the Hebrew Bible is coded causes all higher level nodes such as phrases, clauses and sentences to have gaps at each white space occurrence.\n",
      "\n",
      "LAF-Fabric nearly succeeds in overcoming all those problems.\n",
      "\n",
      "* The compiled resource has node events in approximately the right order.\n",
      "* In your task you can pass a key function to nodes, by which they ambiguous cases can be ordered\n",
      "  (e.g. always nest a clause within a sentence,\n",
      "  even if they are linked to exactly the same stretches of data)\n",
      "* Empty nodes events come between closing events and opening events.\n",
      "\n",
      "Yet this is not enough.\n",
      "There are 17 problematic cases (not much on 2.5 M anchor positions).\n",
      "We show them at the end.\n",
      "\n",
      "Instead of remedying all problems, we will get the trees in a different way, in another notebook.\n",
      "\n",
      "One of the reasons is, that we only use the implicit embedding, while there is, in fact, more information present. We have\n",
      "\n",
      "* parents links from words to phrases to clauses to sentences\n",
      "* word numbers\n",
      "\n",
      "We should use that."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Starting LAF-Fabric"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "\n",
      "import sys\n",
      "import collections\n",
      "\n",
      "from laf.fabric import LafFabric\n",
      "processor = LafFabric(verbose='DETAIL')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.0.0\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload 2\n",
      "API = processor.load('bhs3.txt.hdr', '--', 'trees',\n",
      "{\n",
      "    \"xmlids\": {\n",
      "        \"node\": False,\n",
      "        \"edge\": False,\n",
      "    },\n",
      "    \"features\": {\n",
      "        \"shebanq\": {\n",
      "            \"node\": [\n",
      "                \"db.otype,monads\",\n",
      "                \"ft.text_plain,part_of_speech\",\n",
      "                \"sft.book,chapter,verse\",\n",
      "            ],\n",
      "            \"edge\": [\n",
      "            ],\n",
      "        },\n",
      "    },\n",
      "    'primary': True,\n",
      "})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING a: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: load main: P.node_anchor\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.13s DETAIL: load main: P.node_anchor_items\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.66s DETAIL: load main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.78s DETAIL: load main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.90s DETAIL: load main: P.node_events\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.12s DETAIL: load main: P.node_events_items\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.89s DETAIL: load main: P.node_events_k\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.09s DETAIL: load main: P.node_events_n\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.46s DETAIL: load main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.57s DETAIL: load main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.23s DETAIL: load main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.34s DETAIL: load main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.47s DETAIL: load main: P.primary_data\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.58s DETAIL: load main: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  4.52s DETAIL: load main: F.shebanq_db_monads [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  5.76s DETAIL: load main: F.shebanq_ft_text_plain [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.19s DETAIL: load main: F.shebanq_ft_part_of_speech [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.48s DETAIL: load main: F.shebanq_sft_book [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.50s DETAIL: load main: F.shebanq_sft_chapter [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.52s DETAIL: load main: F.shebanq_sft_verse [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.54s LOGFILE=/Users/dirk/laf-fabric-data/etcbc-bhs3/tasks/bhs3.txt.hdr/trees/__log__trees.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  6.54s INFO: DATA LOADED FROM SOURCE bhs3.txt.hdr AND ANNOX -- FOR TASK trees\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Configuration"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "F = API['F']\n",
      "NE = API['NE']\n",
      "msg = API['msg']\n",
      "outfile = API['outfile']\n",
      "my_file = API['my_file']\n",
      "\n",
      "relevant_nodes = [\n",
      "    (\"word\", ''),\n",
      "    (\"subphrase\", 'p'),\n",
      "    (\"phrase\", 'P'),\n",
      "    (\"clause\", 'C'),\n",
      "    (\"sentence\", 'S'),\n",
      "    (\"_split_\", None),\n",
      "    (\"verse\", None),\n",
      "    (\"chapter\", None),\n",
      "    (\"book\", None),\n",
      "]\n",
      "\n",
      "pos_table = {\n",
      " 'adjective': 'aj',\n",
      " 'adverb': 'av',\n",
      " 'article': 'dt',\n",
      " 'conjunction': 'cj',\n",
      " 'interjection': 'ij',\n",
      " 'interrogative': 'ir',\n",
      " 'negative': 'ng',\n",
      " 'noun': 'n',\n",
      " 'preposition': 'pp',\n",
      " 'pronoun': 'pr',\n",
      " 'verb': 'vb',\n",
      "}\n",
      "\n",
      "select_node = collections.defaultdict(lambda: None)\n",
      "abbrev_node = collections.defaultdict(lambda: None)\n",
      "\n",
      "for (i, (otype, abb)) in enumerate(relevant_nodes):\n",
      "    select_node[otype] = i\n",
      "    abbrev_node[otype] = abb if abb != None else otype\n",
      "\n",
      "split_n = select_node['_split_']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Running"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trees = outfile(\"trees.txt\")\n",
      "anomalies = outfile(\"anomalies.txt\")\n",
      "recent_sentences = collections.deque([], 3)\n",
      "\n",
      "def process_saved():\n",
      "    for (i, (events, book, chapter, verse, verse_label, level)) in enumerate(recent_sentences):\n",
      "        if i == 0:\n",
      "            anomalies.write(\"BEFORE the anomaly {}\\n\".format(verse_label))\n",
      "        elif i == 1:\n",
      "            anomalies.write(\"the anomaly ITSELF {}\\n\".format(verse_label))\n",
      "        elif i == 2:\n",
      "            anomalies.write(\"AFTER the anomaly{}\\n\".format(verse_label))\n",
      "        for (anchor, node, kind) in events:\n",
      "            otype = F.shebanq_db_otype.v(node)\n",
      "            if kind == 3:\n",
      "                if select_node[otype] > split_n:\n",
      "                    continue\n",
      "                level -= 1\n",
      "                anomalies.write('{:>7}-{}{})\\n'.format(anchor, \".\" * level, abbrev_node[otype]))\n",
      "    \n",
      "            elif kind == 2:\n",
      "                if select_node[otype] > split_n:\n",
      "                    continue\n",
      "                level -= 1\n",
      "                anomalies.write('{:>7}-{}{}\u00bb\\n'.format(anchor, \".\" * level, abbrev_node[otype]))\n",
      "    \n",
      "            elif kind == 1:\n",
      "                if select_node[otype] > split_n:\n",
      "                    continue\n",
      "                anomalies.write('{:>7}-{}\u00ab{}\\n'.format(anchor, \".\" * level, abbrev_node[otype]))\n",
      "                level += 1\n",
      "    \n",
      "            elif kind == 0:\n",
      "                if otype == 'book':\n",
      "                    book = F.shebanq_sft_book.v(node)\n",
      "                elif otype == 'chapter':\n",
      "                    chapter = F.shebanq_sft_chapter.v(node)\n",
      "                elif otype == 'verse':\n",
      "                    verse = F.shebanq_sft_verse.v(node)\n",
      "                    verse_label = '{} {}:{}'.format(book, chapter, verse)\n",
      "                    anomalies.write(\"\\n{}\\n\".format(verse_label))\n",
      "                    msg(verse_label)\n",
      "                elif otype == 'word':\n",
      "                    pos = pos_table[F.shebanq_ft_part_of_speech.v(node)]\n",
      "                    text = F.shebanq_ft_text_plain.v(node)\n",
      "                    monads = F.shebanq_db_monads.v(node)\n",
      "                    anomalies.write('{:>7}-{}({} \"{}\" ={}=\\n'.format(anchor, \".\" * level, pos, text, monads))\n",
      "                    level += 1\n",
      "                else:\n",
      "                    anomalies.write('{:>7}-{}({}\\n'.format(anchor, \".\" * level, abbrev_node[otype]))\n",
      "                    level += 1\n",
      "    anomalies.write(\"\\nEND of the anomaly in {}:\\n\".format(verse_label))\n",
      "\n",
      "book = None\n",
      "chapter = None\n",
      "verse = None\n",
      "verse_label = None\n",
      "tree = ''\n",
      "n_warnings = 0\n",
      "level = 0\n",
      "warning = False\n",
      "saved_events = ([], book, chapter, verse, verse_label, level) # we save the events of the current sentence, in case there is an anomaly.\n",
      "\n",
      "for (anchor, events) in NE(key=lambda n:select_node[F.shebanq_db_otype.v(n)], simplify=lambda n:select_node[F.shebanq_db_otype.v(n)] < split_n):\n",
      "    for (node, kind) in events:\n",
      "        saved_events[0].append((anchor, node, kind))\n",
      "        otype = F.shebanq_db_otype.v(node)\n",
      "        if kind == 3:\n",
      "            level -= 1\n",
      "            if select_node[otype] > split_n:\n",
      "                continue\n",
      "            tree += ')'\n",
      "            if otype == 'sentence':\n",
      "                trees.write(tree + \"\\n\")\n",
      "                tree = \"\"\n",
      "                recent_sentences.append(saved_events)\n",
      "                if warning:\n",
      "                    process_saved()\n",
      "                    warning = False\n",
      "                saved_events = ([], book, chapter, verse, verse_label, level)\n",
      "\n",
      "        elif kind == 2:\n",
      "            level -= 1\n",
      "            if select_node[otype] > split_n:\n",
      "                continue\n",
      "            tree += '\u00bb{}\u00bb'.format(abbrev_node[otype])\n",
      "            if otype == 'sentence':\n",
      "                trees.write(tree + \"\\n\")\n",
      "                tree = \"\"\n",
      "                recent_sentences.append(saved_events)\n",
      "                if warning:\n",
      "                    process_saved()\n",
      "                    warning = False\n",
      "                saved_events = ([], book, chapter, verse, verse_label, level)\n",
      "\n",
      "        elif kind == 1:\n",
      "            if select_node[otype] > split_n:\n",
      "                continue\n",
      "            if otype == 'sentence':\n",
      "                if tree != '':\n",
      "                    msg(\"WARNING: material between two sentences in {}: [{}]\".format(verse_label, tree))\n",
      "                    n_warnings += 1\n",
      "                    trees.write(\"{:<15} *** {} ***\\n\".format(verse_label, tree))\n",
      "                    tree = ''\n",
      "                    recent_sentences.append(saved_events)\n",
      "                    if warning:\n",
      "                        process_saved()\n",
      "                        warning = False\n",
      "                    saved_events = ([], book, chapter, verse, verse_label, level)\n",
      "                    warning = True\n",
      "                tree += '{:<15} \u00abS\u00ab '.format(verse_label)\n",
      "            else:\n",
      "                tree += '\u00ab{}\u00ab '.format(abbrev_node[otype])\n",
      "            level += 1\n",
      "\n",
      "        elif kind == 0:\n",
      "            if otype == 'book':\n",
      "                book = F.shebanq_sft_book.v(node)\n",
      "                msg(book)\n",
      "            elif otype == 'chapter':\n",
      "                chapter = F.shebanq_sft_chapter.v(node)\n",
      "            elif otype == 'verse':\n",
      "                verse = F.shebanq_sft_verse.v(node)\n",
      "                verse_label = '{} {}:{}'.format(book, chapter, verse)\n",
      "            elif otype == 'sentence':\n",
      "                if tree != '':\n",
      "                    msg(\"WARNING: material between two sentences in {}: [{}]\".format(verse_label, tree))\n",
      "                    n_warnings += 1\n",
      "                    trees.write(\"{:<15} *** {} ***\\n\".format(verse_label, tree))\n",
      "                    tree = ''\n",
      "                    recent_sentences.append(saved_events)\n",
      "                    if warning:\n",
      "                        process_saved()\n",
      "                        warning = False\n",
      "                    saved_events = ([], book, chapter, verse, verse_label, level)\n",
      "                    warning = True\n",
      "                tree += '{:<15} (S '.format(verse_label)\n",
      "            elif otype == 'word':\n",
      "                pos = pos_table[F.shebanq_ft_part_of_speech.v(node)]\n",
      "                text = F.shebanq_ft_text_plain.v(node)\n",
      "                tree += '({} \"{}\"'.format(pos, text)\n",
      "            else:\n",
      "                tree += '({} '.format(abbrev_node[otype])\n",
      "            level += 1\n",
      "msg(\"There were {} warnings\".format(n_warnings))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    13s Genesis\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    16s Exodus\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    19s Leviticus\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    21s Numbers\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    24s Deuteronomy\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    26s Joshua\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    28s Judges\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s WARNING: material between two sentences in Judges 20:13: [(p (n \"\"))(P ]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    30s I_Samuel\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    32s II_Samuel\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    32s WARNING: material between two sentences in II_Samuel 5:2: [(P (dt \"\"))(C ]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    32s II_Samuel 5:2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    32s WARNING: material between two sentences in II_Samuel 8:4: [(p (n \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    32s II_Samuel 8:3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    32s II_Samuel 8:4\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    34s I_Kings\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    36s II_Kings\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    38s Isaiah\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    40s WARNING: material between two sentences in Isaiah 55:13: [(P (cj \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    40s Isaiah 55:13\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    41s Jeremiah\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    44s Ezekiel\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    44s WARNING: material between two sentences in Ezekiel 13:15: [(P (dt \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    44s Ezekiel 13:15\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    47s Hosea\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    47s Joel\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    47s Amos\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    47s Obadiah\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    47s Jonah\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s Micah\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s Nahum\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s Habakkuk\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s Zephaniah\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s Haggai\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s Zechariah\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    49s Malachi\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    49s Psalms\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    49s WARNING: material between two sentences in Psalms 31:20: [(P (dt \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    50s WARNING: material between two sentences in Psalms 68:5: [(P (dt \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    51s Job\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    53s Proverbs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    53s WARNING: material between two sentences in Proverbs 23:24: [(P (cj \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    53s Proverbs 23:24\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    54s Ruth\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    54s WARNING: material between two sentences in Ruth 3:17: [(P (pp \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    54s Canticles\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    54s Ecclesiastes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    54s Lamentations\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    55s WARNING: material between two sentences in Lamentations 2:2: [(P (cj \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    55s Lamentations 2:2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    55s WARNING: material between two sentences in Lamentations 4:16: [(P (cj \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    55s WARNING: material between two sentences in Lamentations 5:3: [(P (cj \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    55s Lamentations 5:3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    55s WARNING: material between two sentences in Lamentations 5:5: [(P (cj \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    55s WARNING: material between two sentences in Lamentations 5:7: [(P (cj \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    55s Lamentations 5:7\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    55s WARNING: material between two sentences in Lamentations 5:7: [(P (cj \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    55s WARNING: material between two sentences in Lamentations 5:7: [Lamentations 5:7 (S (C ]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    55s Esther\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    55s Daniel\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    55s WARNING: material between two sentences in Daniel 2:43: [(cj \"\")]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    55s Daniel 2:43\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    56s Ezra\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    57s Nehemiah\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    57s I_Chronicles\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    59s II_Chronicles\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 1m 01s There were 17 warnings\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API['close']()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " 2m 32s Results directory:\n",
        "/Users/dirk/laf-fabric-data/etcbc-bhs3/tasks/bhs3.txt.hdr/trees\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "__log__trees.txt                       2451 Sat Mar 22 17:46:46 2014\n",
        "anomalies.txt                         16798 Sat Mar 22 17:46:46 2014\n",
        "trees.txt                           8743654 Sat Mar 22 17:46:46 2014\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -n 25 {my_file('trees.txt')}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Genesis 1:1     (S (C (P (pp \"\u05d1\")(n \"\u05e8\u05d0\u05e9\u05c1\u05d9\u05ea\"))(P (vb \"\u05d1\u05e8\u05d0\"))(P (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\"))(P (p (pp \"\u05d0\u05ea\")(dt \"\u05d4\")(n \"\u05e9\u05c1\u05de\u05d9\u05dd\"))(cj \"\u05d5\")(p (pp \"\u05d0\u05ea\")(dt \"\u05d4\")(n \"\u05d0\u05e8\u05e5\")))))\r\n",
        "Genesis 1:2     (S (C (P (cj \"\u05d5\"))(P (dt \"\u05d4\")(n \"\u05d0\u05e8\u05e5\"))(P (vb \"\u05d4\u05d9\u05ea\u05d4\"))(P (p (n \"\u05ea\u05d4\u05d5\"))(cj \"\u05d5\")(p (n \"\u05d1\u05d4\u05d5\")))))\r\n",
        "Genesis 1:2     (S (C (P (cj \"\u05d5\"))(P (n \"\u05d7\u05e9\u05c1\u05da\"))(P (pp \"\u05e2\u05dc\")(p (n \"\u05e4\u05e0\u05d9\"))(p (n \"\u05ea\u05d4\u05d5\u05dd\")))))\r\n",
        "Genesis 1:2     (S (C (P (cj \"\u05d5\"))(P (p (n \"\u05e8\u05d5\u05d7\"))(p (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\")))(P (vb \"\u05de\u05e8\u05d7\u05e4\u05ea\"))(P (pp \"\u05e2\u05dc\")(p (n \"\u05e4\u05e0\u05d9\"))(p (dt \"\u05d4\")(n \"\u05de\u05d9\u05dd\")))))\r\n",
        "Genesis 1:3     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d0\u05de\u05e8\"))(P (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\"))))\r\n",
        "Genesis 1:3     (S (C (P (vb \"\u05d9\u05d4\u05d9\"))(P (n \"\u05d0\u05d5\u05e8\"))))\r\n",
        "Genesis 1:3     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d4\u05d9\"))(P (n \"\u05d0\u05d5\u05e8\"))))\r\n",
        "Genesis 1:4     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05e8\u05d0\"))(P (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\"))(P (pp \"\u05d0\u05ea\")(dt \"\u05d4\")(n \"\u05d0\u05d5\u05e8\")))(C (P (cj \"\u05db\u05d9\"))(P (vb \"\u05d8\u05d5\u05d1\"))))\r\n",
        "Genesis 1:4     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d1\u05d3\u05dc\"))(P (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\"))(P (p (n \"\u05d1\u05d9\u05df\")(dt \"\u05d4\")(n \"\u05d0\u05d5\u05e8\"))(cj \"\u05d5\")(p (n \"\u05d1\u05d9\u05df\")(dt \"\u05d4\")(n \"\u05d7\u05e9\u05c1\u05da\")))))\r\n",
        "Genesis 1:5     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05e7\u05e8\u05d0\"))(P (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\"))(P (pp \"\u05dc\")(dt \"\")(n \"\u05d0\u05d5\u05e8\"))(P (n \"\u05d9\u05d5\u05dd\"))))\r\n",
        "Genesis 1:5     (S (C (P (cj \"\u05d5\"))(P (pp \"\u05dc\")(dt \"\")(n \"\u05d7\u05e9\u05c1\u05da\"))(P (vb \"\u05e7\u05e8\u05d0\"))(P (n \"\u05dc\u05d9\u05dc\u05d4\"))))\r\n",
        "Genesis 1:5     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d4\u05d9\"))(P (n \"\u05e2\u05e8\u05d1\"))))\r\n",
        "Genesis 1:5     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d4\u05d9\"))(P (n \"\u05d1\u05e7\u05e8\"))))\r\n",
        "Genesis 1:5     (S (C (P (p (n \"\u05d9\u05d5\u05dd\"))(p (n \"\u05d0\u05d7\u05d3\")))))\r\n",
        "Genesis 1:6     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d0\u05de\u05e8\"))(P (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\"))))\r\n",
        "Genesis 1:6     (S (C (P (vb \"\u05d9\u05d4\u05d9\"))(P (n \"\u05e8\u05e7\u05d9\u05e2\"))(P (pp \"\u05d1\")(p (n \"\u05ea\u05d5\u05da\"))(p (dt \"\u05d4\")(n \"\u05de\u05d9\u05dd\")))))\r\n",
        "Genesis 1:6     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d4\u05d9\"))(P (vb \"\u05de\u05d1\u05d3\u05d9\u05dc\"))(P (n \"\u05d1\u05d9\u05df\")(n \"\u05de\u05d9\u05dd\")(pp \"\u05dc\")(n \"\u05de\u05d9\u05dd\"))))\r\n",
        "Genesis 1:7     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05e2\u05e9\u05c2\"))(P (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\"))(P (pp \"\u05d0\u05ea\")(dt \"\u05d4\")(n \"\u05e8\u05e7\u05d9\u05e2\"))))\r\n",
        "Genesis 1:7     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d1\u05d3\u05dc\"))(P (n \"\u05d1\u05d9\u05df\")(dt \"\u05d4\")(n \"\u05de\u05d9\u05dd\"))\u00bbC\u00bb(C (P (cj \"\u05d0\u05e9\u05c1\u05e8\"))(P (pp \"\u05de\")(n \"\u05ea\u05d7\u05ea\")(pp \"\u05dc\")(dt \"\")(n \"\u05e8\u05e7\u05d9\u05e2\")))\u00abC\u00ab (P (cj \"\u05d5\"))(P (n \"\u05d1\u05d9\u05df\")(dt \"\u05d4\")(n \"\u05de\u05d9\u05dd\")))(C (P (cj \"\u05d0\u05e9\u05c1\u05e8\"))(P (pp \"\u05de\")(pp \"\u05e2\u05dc\")(pp \"\u05dc\")(dt \"\")(n \"\u05e8\u05e7\u05d9\u05e2\"))))\r\n",
        "Genesis 1:7     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d4\u05d9\"))(P (av \"\u05db\u05df\"))))\r\n",
        "Genesis 1:8     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05e7\u05e8\u05d0\"))(P (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\"))(P (pp \"\u05dc\")(dt \"\")(n \"\u05e8\u05e7\u05d9\u05e2\"))(P (n \"\u05e9\u05c1\u05de\u05d9\u05dd\"))))\r\n",
        "Genesis 1:8     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d4\u05d9\"))(P (n \"\u05e2\u05e8\u05d1\"))))\r\n",
        "Genesis 1:8     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d4\u05d9\"))(P (n \"\u05d1\u05e7\u05e8\"))))\r\n",
        "Genesis 1:8     (S (C (P (p (n \"\u05d9\u05d5\u05dd\"))(p (aj \"\u05e9\u05c1\u05e0\u05d9\")))))\r\n",
        "Genesis 1:9     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d0\u05de\u05e8\"))(P (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\"))))\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Anomalies"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* we have suspends and resumes of nodes. Probably to be changed into true embedding.\n",
      "* there are empty words (such as the dt (determiner) in Genesis 1:7.\n",
      "* there are also empty words not attached to non-empty words. These have posed problems in an earlier version of LAF-Fabric,\n",
      "  where node events were not ordered properly.\n",
      "\n",
      "Node events per anchor should be ordered in such a way that closing/suspendig events of non-empty nodes at that anchor come first,\n",
      "followed by events for empty nodes, followed by opening/resuming events."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!grep 'Lamentations 5:3' {my_file('trees.txt')}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Lamentations 5:3 (S (C (P (n \"\u05d9\u05ea\u05d5\u05de\u05d9\u05dd\"))(P (vb \"\u05d4\u05d9\u05d9\u05e0\u05d5\"))))\r\n",
        "Lamentations 5:3 *** (P (cj \"\")) ***\r\n",
        "Lamentations 5:3 (S (C (P (n \"\u05d0\u05d9\u05df\"))(P (n \"\u05d0\u05d1\"))))\r\n",
        "Lamentations 5:3 (S (C (P (n \"\u05d0\u05de\u05ea\u05d9\u05e0\u05d5\"))(P (pp \"\u05db\")(n \"\u05d0\u05dc\u05de\u05e0\u05d5\u05ea\"))))\r\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!grep 'Judges 20:13' {my_file('trees.txt')}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Judges 20:13    (S (C (P (cj \"\u05d5\"))(P (av \"\u05e2\u05ea\u05d4\"))))\r\n",
        "Judges 20:13    (S (C (P (vb \"\u05ea\u05e0\u05d5\"))(P (pp \"\u05d0\u05ea\")(dt \"\u05d4\")(n \"\u05d0\u05e0\u05e9\u05c1\u05d9\u05dd\")(p (n \"\u05d1\u05e0\u05d9\"))(p (n \"\u05d1\u05dc\u05d9\u05e2\u05dc\"))))(C (P (cj \"\u05d0\u05e9\u05c1\u05e8\"))(P (pp \"\u05d1\")(dt \"\")(n \"\u05d2\u05d1\u05e2\u05d4\"))))\r\n",
        "Judges 20:13    (S (C (P (cj \"\u05d5\"))(P (vb \"\u05e0\u05de\u05d9\u05ea\u05dd\"))))\r\n",
        "Judges 20:13    (S (C (P (cj \"\u05d5\"))(P (vb \"\u05e0\u05d1\u05e2\u05e8\u05d4\"))(P (n \"\u05e8\u05e2\u05d4\"))(P (pp \"\u05de\")(n \"\u05d9\u05e9\u05c2\u05e8\u05d0\u05dc\"))))\r\n",
        "Judges 20:13    (S (C (P (cj \"\u05d5\"))(P (ng \"\u05dc\u05d0\"))(P (vb \"\u05d0\u05d1\u05d5\"))\u00bbP\u00bb\u00bbC\u00bb\u00bbS\u00bb\r\n",
        "Judges 20:13    *** (p (n \"\"))(P  ***\r\n",
        "Judges 20:13    \u00abS\u00ab \u00abC\u00ab \u00abP\u00ab (p (n \"\u05d1\u05e0\u05d9\u05de\u05df\"))))(C (P (pp \"\u05dc\")(vb \"\u05e9\u05c1\u05de\u05e2\"))(P (pp \"\u05d1\")(p (n \"\u05e7\u05d5\u05dc\"))(p (n \"\u05d0\u05d7\u05d9\u05d4\u05dd\"))(p (n \"\u05d1\u05e0\u05d9\"))(p (n \"\u05d9\u05e9\u05c2\u05e8\u05d0\u05dc\")))))\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}