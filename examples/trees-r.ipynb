{
 "metadata": {
  "name": "",
  "signature": "sha256:c6d8b28c8ffaaf3e23e381acdfd9b5f3747b630d66374e3a5487eed29231a741"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"http://laf-fabric.readthedocs.org/en/latest/\" target=\"_blank\"><img align=\"left\" src=\"images/laf-fabric-xsmall.png\"/></a>\n",
      "<a href=\"http://www.godgeleerdheid.vu.nl/etcbc\" target=\"_blank\"><img align=\"left\" src=\"images/VU-ETCBC-xsmall.png\"/></a>\n",
      "<a href=\"http://tla.mpi.nl\" target=\"_blank\"><img align=\"right\" src=\"images/TLA-xsmall.png\"/></a>\n",
      "<a href=\"http://www.dans.knaw.nl\" target=\"_blank\"><img align=\"right\"src=\"images/DANS-xsmall.png\"/></a>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Trees - the rough path"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We show the embedding of nodes annotated as sentences, clauses, phrases, subphrases and words.\n",
      "We put them in a format (eventually) such that they can be read by TQUERY.\n",
      "Then Rens Bod and Andreas van Cranenburgh can do interesting business with it.\n",
      "\n",
      "The approach chosen in this notebook turns out to have problems.\n",
      "\n",
      "Method\n",
      "======\n",
      "We walk through all anchor positions of the primary data, and follow the node events at that position.\n",
      "LAF-Fabric tries hard to generate node events in an order that respects the factual embedding of nodes.\n",
      "\n",
      "However, some nodes have gaps, some nodes are linked to regions with zero length, and some nodes have identical regions. \n",
      "Moreover, the way our current LAF resource of the Hebrew Bible is coded causes all higher level nodes such as phrases, clauses and sentences to have gaps at each white space occurrence.\n",
      "\n",
      "LAF-Fabric nearly succeeds in overcoming all those problems.\n",
      "\n",
      "* The compiled resource has node events in approximately the right order.\n",
      "* In your task you can pass a key function to nodes, by which they ambiguous cases can be ordered\n",
      "  (e.g. always nest a clause within a sentence,\n",
      "  even if they are linked to exactly the same stretches of data)\n",
      "* Empty nodes events come between closing events and opening events.\n",
      "\n",
      "Yet this is not enough.\n",
      "There are 17 problematic cases (not much on 2.5 M anchor positions).\n",
      "We show them at the end.\n",
      "\n",
      "Instead of remedying all problems, we will get the trees in a different way, in another notebook.\n",
      "\n",
      "One of the reasons is, that we only use the implicit embedding, while there is, in fact, more information present. We have\n",
      "\n",
      "* parents links from words to phrases to clauses to sentences\n",
      "* word numbers\n",
      "\n",
      "We should use that."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Starting LAF-Fabric"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "\n",
      "import sys\n",
      "import collections\n",
      "\n",
      "from laf.fabric import LafFabric\n",
      "processor = LafFabric(verbose='DETAIL')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s This is LAF-Fabric 4.2.15\n",
        "http://laf-fabric.readthedocs.org/en/latest/texts/API-reference.html\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload 2\n",
      "API = processor.load('bhs3', '--', 'trees',\n",
      "{\n",
      "    \"xmlids\": {\"node\": False, \"edge\": False},\n",
      "    \"features\": (\"otype monads text_plain part_of_speech book chapter verse\", \"\"),\n",
      "    'primary': True,\n",
      "})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s LOADING API: please wait ... \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING m: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s INFO: USING DATA COMPILED AT: 2014-06-27T12-21-04\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.00s DETAIL: COMPILING a: UP TO DATE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.01s DETAIL: load main: P.node_anchor\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.08s DETAIL: load main: P.node_anchor_items\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.34s DETAIL: load main: G.node_anchor_min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.40s DETAIL: load main: G.node_anchor_max\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.45s DETAIL: load main: P.node_events\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.53s DETAIL: load main: P.node_events_items\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.82s DETAIL: load main: P.node_events_k\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  0.90s DETAIL: load main: P.node_events_n\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.06s DETAIL: load main: G.node_sort\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.11s DETAIL: load main: G.node_sort_inv\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.56s DETAIL: load main: G.edges_from\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.62s DETAIL: load main: G.edges_to\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.68s DETAIL: load main: P.primary_data\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  1.75s DETAIL: load main: F.shebanq_db_monads [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  2.60s DETAIL: load main: F.shebanq_db_otype [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.27s DETAIL: load main: F.shebanq_ft_part_of_speech [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.49s DETAIL: load main: F.shebanq_ft_text_plain [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.76s DETAIL: load main: F.shebanq_sft_book [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.78s DETAIL: load main: F.shebanq_sft_chapter [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.79s DETAIL: load main: F.shebanq_sft_verse [node] \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.81s LOGFILE=/Users/dirk/laf-fabric-output/bhs3/trees/__log__trees.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  3.81s INFO: DATA LOADED FROM SOURCE bhs3 AND ANNOX -- FOR TASK trees AT 2014-06-27T12-32-50\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Configuration"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "F = API['F']\n",
      "NE = API['NE']\n",
      "msg = API['msg']\n",
      "outfile = API['outfile']\n",
      "my_file = API['my_file']\n",
      "\n",
      "relevant_nodes = [\n",
      "    (\"word\", ''),\n",
      "    (\"subphrase\", 'p'),\n",
      "    (\"phrase\", 'P'),\n",
      "    (\"clause\", 'C'),\n",
      "    (\"sentence\", 'S'),\n",
      "    (\"_split_\", None),\n",
      "    (\"verse\", None),\n",
      "    (\"chapter\", None),\n",
      "    (\"book\", None),\n",
      "]\n",
      "\n",
      "pos_table = {\n",
      " 'adjective': 'aj',\n",
      " 'adverb': 'av',\n",
      " 'article': 'dt',\n",
      " 'conjunction': 'cj',\n",
      " 'interjection': 'ij',\n",
      " 'interrogative': 'ir',\n",
      " 'negative': 'ng',\n",
      " 'noun': 'n',\n",
      " 'preposition': 'pp',\n",
      " 'pronoun': 'pr',\n",
      " 'verb': 'vb',\n",
      "}\n",
      "\n",
      "select_node = collections.defaultdict(lambda: None)\n",
      "abbrev_node = collections.defaultdict(lambda: None)\n",
      "\n",
      "for (i, (otype, abb)) in enumerate(relevant_nodes):\n",
      "    select_node[otype] = i\n",
      "    abbrev_node[otype] = abb if abb != None else otype\n",
      "\n",
      "split_n = select_node['_split_']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Running"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trees = outfile(\"trees.txt\")\n",
      "anomalies = outfile(\"anomalies.txt\")\n",
      "recent_sentences = collections.deque([], 3)\n",
      "\n",
      "def process_saved():\n",
      "    for (i, (events, book, chapter, verse, verse_label, level)) in enumerate(recent_sentences):\n",
      "        if i == 0:\n",
      "            anomalies.write(\"BEFORE the anomaly {}\\n\".format(verse_label))\n",
      "        elif i == 1:\n",
      "            anomalies.write(\"the anomaly ITSELF {}\\n\".format(verse_label))\n",
      "        elif i == 2:\n",
      "            anomalies.write(\"AFTER the anomaly{}\\n\".format(verse_label))\n",
      "        for (anchor, node, kind) in events:\n",
      "            otype = F.otype.v(node)\n",
      "            if kind == 3:\n",
      "                if select_node[otype] > split_n:\n",
      "                    continue\n",
      "                level -= 1\n",
      "                anomalies.write('{:>7}-{}{})\\n'.format(anchor, \".\" * level, abbrev_node[otype]))\n",
      "    \n",
      "            elif kind == 2:\n",
      "                if select_node[otype] > split_n:\n",
      "                    continue\n",
      "                level -= 1\n",
      "                anomalies.write('{:>7}-{}{}\u00bb\\n'.format(anchor, \".\" * level, abbrev_node[otype]))\n",
      "    \n",
      "            elif kind == 1:\n",
      "                if select_node[otype] > split_n:\n",
      "                    continue\n",
      "                anomalies.write('{:>7}-{}\u00ab{}\\n'.format(anchor, \".\" * level, abbrev_node[otype]))\n",
      "                level += 1\n",
      "    \n",
      "            elif kind == 0:\n",
      "                if otype == 'book':\n",
      "                    book = F.book.v(node)\n",
      "                elif otype == 'chapter':\n",
      "                    chapter = F.chapter.v(node)\n",
      "                elif otype == 'verse':\n",
      "                    verse = F.verse.v(node)\n",
      "                    verse_label = '{} {}:{}'.format(book, chapter, verse)\n",
      "                    anomalies.write(\"\\n{}\\n\".format(verse_label))\n",
      "                    msg(verse_label)\n",
      "                elif otype == 'word':\n",
      "                    pos = pos_table[F.part_of_speech.v(node)]\n",
      "                    text = F.text_plain.v(node)\n",
      "                    monads = F.monads.v(node)\n",
      "                    anomalies.write('{:>7}-{}({} \"{}\" ={}=\\n'.format(anchor, \".\" * level, pos, text, monads))\n",
      "                    level += 1\n",
      "                else:\n",
      "                    anomalies.write('{:>7}-{}({}\\n'.format(anchor, \".\" * level, abbrev_node[otype]))\n",
      "                    level += 1\n",
      "    anomalies.write(\"\\nEND of the anomaly in {}:\\n\".format(verse_label))\n",
      "\n",
      "book = None\n",
      "chapter = None\n",
      "verse = None\n",
      "verse_label = None\n",
      "tree = ''\n",
      "n_warnings = 0\n",
      "level = 0\n",
      "warning = False\n",
      "saved_events = ([], book, chapter, verse, verse_label, level) # we save the events of the current sentence, in case there is an anomaly.\n",
      "\n",
      "for (anchor, events) in NE(key=lambda n:select_node[F.otype.v(n)], simplify=lambda n:select_node[F.otype.v(n)] < split_n):\n",
      "    for (node, kind) in events:\n",
      "        saved_events[0].append((anchor, node, kind))\n",
      "        otype = F.otype.v(node)\n",
      "        if kind == 3:\n",
      "            level -= 1\n",
      "            if select_node[otype] > split_n:\n",
      "                continue\n",
      "            tree += ')'\n",
      "            if otype == 'sentence':\n",
      "                trees.write(tree + \"\\n\")\n",
      "                tree = \"\"\n",
      "                recent_sentences.append(saved_events)\n",
      "                if warning:\n",
      "                    process_saved()\n",
      "                    warning = False\n",
      "                saved_events = ([], book, chapter, verse, verse_label, level)\n",
      "\n",
      "        elif kind == 2:\n",
      "            level -= 1\n",
      "            if select_node[otype] > split_n:\n",
      "                continue\n",
      "            tree += '\u00bb{}\u00bb'.format(abbrev_node[otype])\n",
      "            if otype == 'sentence':\n",
      "                trees.write(tree + \"\\n\")\n",
      "                tree = \"\"\n",
      "                recent_sentences.append(saved_events)\n",
      "                if warning:\n",
      "                    process_saved()\n",
      "                    warning = False\n",
      "                saved_events = ([], book, chapter, verse, verse_label, level)\n",
      "\n",
      "        elif kind == 1:\n",
      "            if select_node[otype] > split_n:\n",
      "                continue\n",
      "            if otype == 'sentence':\n",
      "                if tree != '':\n",
      "                    msg(\"WARNING: material between two sentences in {}: [{}]\".format(verse_label, tree))\n",
      "                    n_warnings += 1\n",
      "                    trees.write(\"{:<15} *** {} ***\\n\".format(verse_label, tree))\n",
      "                    tree = ''\n",
      "                    recent_sentences.append(saved_events)\n",
      "                    if warning:\n",
      "                        process_saved()\n",
      "                        warning = False\n",
      "                    saved_events = ([], book, chapter, verse, verse_label, level)\n",
      "                    warning = True\n",
      "                tree += '{:<15} \u00abS\u00ab '.format(verse_label)\n",
      "            else:\n",
      "                tree += '\u00ab{}\u00ab '.format(abbrev_node[otype])\n",
      "            level += 1\n",
      "\n",
      "        elif kind == 0:\n",
      "            if otype == 'book':\n",
      "                book = F.book.v(node)\n",
      "                msg(book)\n",
      "            elif otype == 'chapter':\n",
      "                chapter = F.chapter.v(node)\n",
      "            elif otype == 'verse':\n",
      "                verse = F.verse.v(node)\n",
      "                verse_label = '{} {}:{}'.format(book, chapter, verse)\n",
      "            elif otype == 'sentence':\n",
      "                if tree != '':\n",
      "                    msg(\"WARNING: material between two sentences in {}: [{}]\".format(verse_label, tree))\n",
      "                    n_warnings += 1\n",
      "                    trees.write(\"{:<15} *** {} ***\\n\".format(verse_label, tree))\n",
      "                    tree = ''\n",
      "                    recent_sentences.append(saved_events)\n",
      "                    if warning:\n",
      "                        process_saved()\n",
      "                        warning = False\n",
      "                    saved_events = ([], book, chapter, verse, verse_label, level)\n",
      "                    warning = True\n",
      "                tree += '{:<15} (S '.format(verse_label)\n",
      "            elif otype == 'word':\n",
      "                pos = pos_table[F.part_of_speech.v(node)]\n",
      "                text = F.text_plain.v(node)\n",
      "                tree += '({} \"{}\"'.format(pos, text)\n",
      "            else:\n",
      "                tree += '({} '.format(abbrev_node[otype])\n",
      "            level += 1\n",
      "msg(\"There were {} warnings\".format(n_warnings))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  7.67s Genesis\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    11s Exodus\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    13s Leviticus\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    15s Numbers\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    17s Deuteronomy\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    20s Joshua\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    21s Judges\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    23s WARNING: material between two sentences in Judges 20:13: [(p (n \"\"))(P ]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    23s I_Samuel\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    25s II_Samuel\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    25s WARNING: material between two sentences in II_Samuel 5:2: [(P (dt \"\"))(C ]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    25s II_Samuel 5:2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    25s WARNING: material between two sentences in II_Samuel 8:4: [(p (n \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    25s II_Samuel 8:3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    25s II_Samuel 8:4\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    26s I_Kings\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    28s II_Kings\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    31s Isaiah\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    33s WARNING: material between two sentences in Isaiah 55:13: [(P (cj \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    33s Isaiah 55:13\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    33s Jeremiah\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    36s Ezekiel\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    37s WARNING: material between two sentences in Ezekiel 13:15: [(P (dt \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    37s Ezekiel 13:15\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    39s Hosea\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    39s Joel\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    40s Amos\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    40s Obadiah\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    40s Jonah\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    40s Micah\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    40s Nahum\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    40s Habakkuk\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    40s Zephaniah\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    41s Haggai\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    41s Zechariah\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    41s Malachi\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    42s Psalms\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    42s WARNING: material between two sentences in Psalms 31:20: [(P (dt \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    43s WARNING: material between two sentences in Psalms 68:5: [(P (dt \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    45s Job\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    46s Proverbs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    47s WARNING: material between two sentences in Proverbs 23:24: [(P (cj \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    47s Proverbs 23:24\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    47s Ruth\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    47s WARNING: material between two sentences in Ruth 3:17: [(P (pp \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    47s Canticles\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    47s Ecclesiastes\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s Lamentations\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s WARNING: material between two sentences in Lamentations 2:2: [(P (cj \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s Lamentations 2:2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s WARNING: material between two sentences in Lamentations 4:16: [(P (cj \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s WARNING: material between two sentences in Lamentations 5:3: [(P (cj \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s Lamentations 5:3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s WARNING: material between two sentences in Lamentations 5:5: [(P (cj \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s WARNING: material between two sentences in Lamentations 5:7: [(P (cj \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s Lamentations 5:7\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s WARNING: material between two sentences in Lamentations 5:7: [(P (cj \"\"))]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s WARNING: material between two sentences in Lamentations 5:7: [Lamentations 5:7 (S (C ]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s Esther\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    48s Daniel\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    49s WARNING: material between two sentences in Daniel 2:43: [(cj \"\")]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    49s Daniel 2:43\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    50s Ezra\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    50s Nehemiah\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    51s I_Chronicles\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    53s II_Chronicles\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    55s There were 17 warnings\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API['close']()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    57s Results directory:\n",
        "/Users/dirk/laf-fabric-output/bhs3/trees\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        ".DS_Store                              6148 Wed Apr 30 16:30:02 2014\n",
        "__log__trees.txt                       2473 Fri Jun 27 14:33:47 2014\n",
        "anomalies.txt                         16798 Fri Jun 27 14:33:47 2014\n",
        "coor.txt                              70830 Wed Apr 30 20:57:45 2014\n",
        "depths.txt                           714284 Wed Apr 30 20:57:44 2014\n",
        "objects-deut-new.txt                    966 Fri Apr 25 09:53:16 2014\n",
        "objects-deut-old.txt                    966 Fri Apr 25 09:51:15 2014\n",
        "objects.txt                           15416 Fri Apr 25 09:47:18 2014\n",
        "tgrep_result.txt                    4916101 Wed Apr 30 20:57:37 2014\n",
        "tree_notabene-2014-04-30.txt         111037 Wed Apr 30 20:51:21 2014\n",
        "tree_notabene.txt                    117385 Sat May 31 13:37:33 2014\n",
        "trees-nocoor.txt                      13914 Mon Apr 28 09:59:30 2014\n",
        "trees-nosisters.txt                   13928 Mon Apr 28 09:59:30 2014\n",
        "trees-notransform.txt                   501 Mon Apr 28 09:47:29 2014\n",
        "trees-simple.txt                    8310229 Tue May 27 15:54:22 2014\n",
        "trees-transformed.txt                   371 Mon Apr 28 09:47:43 2014\n",
        "trees.t2c                          12361153 Wed Apr 30 20:57:22 2014\n",
        "trees.txt                           8743654 Fri Jun 27 14:33:47 2014\n",
        "trees2014-04-30.txt                10626155 Wed Apr 30 20:56:26 2014\n",
        "trees_fixed_20.txt                   150015 Sat May 31 13:37:33 2014\n",
        "trees_random_20-2014-04-30.txt       150015 Wed Apr 30 20:51:21 2014\n",
        "trees_random_20.txt                  131251 Sat May 31 13:37:33 2014\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -n 25 {my_file('trees.txt')}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Genesis 1:1     (S (C (P (pp \"\u05d1\")(n \"\u05e8\u05d0\u05e9\u05c1\u05d9\u05ea\"))(P (vb \"\u05d1\u05e8\u05d0\"))(P (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\"))(P (p (pp \"\u05d0\u05ea\")(dt \"\u05d4\")(n \"\u05e9\u05c1\u05de\u05d9\u05dd\"))(cj \"\u05d5\")(p (pp \"\u05d0\u05ea\")(dt \"\u05d4\")(n \"\u05d0\u05e8\u05e5\")))))\r\n",
        "Genesis 1:2     (S (C (P (cj \"\u05d5\"))(P (dt \"\u05d4\")(n \"\u05d0\u05e8\u05e5\"))(P (vb \"\u05d4\u05d9\u05ea\u05d4\"))(P (p (n \"\u05ea\u05d4\u05d5\"))(cj \"\u05d5\")(p (n \"\u05d1\u05d4\u05d5\")))))\r\n",
        "Genesis 1:2     (S (C (P (cj \"\u05d5\"))(P (n \"\u05d7\u05e9\u05c1\u05da\"))(P (pp \"\u05e2\u05dc\")(p (n \"\u05e4\u05e0\u05d9\"))(p (n \"\u05ea\u05d4\u05d5\u05dd\")))))\r\n",
        "Genesis 1:2     (S (C (P (cj \"\u05d5\"))(P (p (n \"\u05e8\u05d5\u05d7\"))(p (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\")))(P (vb \"\u05de\u05e8\u05d7\u05e4\u05ea\"))(P (pp \"\u05e2\u05dc\")(p (n \"\u05e4\u05e0\u05d9\"))(p (dt \"\u05d4\")(n \"\u05de\u05d9\u05dd\")))))\r\n",
        "Genesis 1:3     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d0\u05de\u05e8\"))(P (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\"))))\r\n",
        "Genesis 1:3     (S (C (P (vb \"\u05d9\u05d4\u05d9\"))(P (n \"\u05d0\u05d5\u05e8\"))))\r\n",
        "Genesis 1:3     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d4\u05d9\"))(P (n \"\u05d0\u05d5\u05e8\"))))\r\n",
        "Genesis 1:4     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05e8\u05d0\"))(P (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\"))(P (pp \"\u05d0\u05ea\")(dt \"\u05d4\")(n \"\u05d0\u05d5\u05e8\")))(C (P (cj \"\u05db\u05d9\"))(P (vb \"\u05d8\u05d5\u05d1\"))))\r\n",
        "Genesis 1:4     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d1\u05d3\u05dc\"))(P (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\"))(P (p (n \"\u05d1\u05d9\u05df\")(dt \"\u05d4\")(n \"\u05d0\u05d5\u05e8\"))(cj \"\u05d5\")(p (n \"\u05d1\u05d9\u05df\")(dt \"\u05d4\")(n \"\u05d7\u05e9\u05c1\u05da\")))))\r\n",
        "Genesis 1:5     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05e7\u05e8\u05d0\"))(P (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\"))(P (pp \"\u05dc\")(dt \"\")(n \"\u05d0\u05d5\u05e8\"))(P (n \"\u05d9\u05d5\u05dd\"))))\r\n",
        "Genesis 1:5     (S (C (P (cj \"\u05d5\"))(P (pp \"\u05dc\")(dt \"\")(n \"\u05d7\u05e9\u05c1\u05da\"))(P (vb \"\u05e7\u05e8\u05d0\"))(P (n \"\u05dc\u05d9\u05dc\u05d4\"))))\r\n",
        "Genesis 1:5     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d4\u05d9\"))(P (n \"\u05e2\u05e8\u05d1\"))))\r\n",
        "Genesis 1:5     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d4\u05d9\"))(P (n \"\u05d1\u05e7\u05e8\"))))\r\n",
        "Genesis 1:5     (S (C (P (p (n \"\u05d9\u05d5\u05dd\"))(p (n \"\u05d0\u05d7\u05d3\")))))\r\n",
        "Genesis 1:6     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d0\u05de\u05e8\"))(P (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\"))))\r\n",
        "Genesis 1:6     (S (C (P (vb \"\u05d9\u05d4\u05d9\"))(P (n \"\u05e8\u05e7\u05d9\u05e2\"))(P (pp \"\u05d1\")(p (n \"\u05ea\u05d5\u05da\"))(p (dt \"\u05d4\")(n \"\u05de\u05d9\u05dd\")))))\r\n",
        "Genesis 1:6     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d4\u05d9\"))(P (vb \"\u05de\u05d1\u05d3\u05d9\u05dc\"))(P (n \"\u05d1\u05d9\u05df\")(n \"\u05de\u05d9\u05dd\")(pp \"\u05dc\")(n \"\u05de\u05d9\u05dd\"))))\r\n",
        "Genesis 1:7     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05e2\u05e9\u05c2\"))(P (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\"))(P (pp \"\u05d0\u05ea\")(dt \"\u05d4\")(n \"\u05e8\u05e7\u05d9\u05e2\"))))\r\n",
        "Genesis 1:7     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d1\u05d3\u05dc\"))(P (n \"\u05d1\u05d9\u05df\")(dt \"\u05d4\")(n \"\u05de\u05d9\u05dd\"))\u00bbC\u00bb(C (P (cj \"\u05d0\u05e9\u05c1\u05e8\"))(P (pp \"\u05de\")(n \"\u05ea\u05d7\u05ea\")(pp \"\u05dc\")(dt \"\")(n \"\u05e8\u05e7\u05d9\u05e2\")))\u00abC\u00ab (P (cj \"\u05d5\"))(P (n \"\u05d1\u05d9\u05df\")(dt \"\u05d4\")(n \"\u05de\u05d9\u05dd\")))(C (P (cj \"\u05d0\u05e9\u05c1\u05e8\"))(P (pp \"\u05de\")(pp \"\u05e2\u05dc\")(pp \"\u05dc\")(dt \"\")(n \"\u05e8\u05e7\u05d9\u05e2\"))))\r\n",
        "Genesis 1:7     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d4\u05d9\"))(P (av \"\u05db\u05df\"))))\r\n",
        "Genesis 1:8     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05e7\u05e8\u05d0\"))(P (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\"))(P (pp \"\u05dc\")(dt \"\")(n \"\u05e8\u05e7\u05d9\u05e2\"))(P (n \"\u05e9\u05c1\u05de\u05d9\u05dd\"))))\r\n",
        "Genesis 1:8     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d4\u05d9\"))(P (n \"\u05e2\u05e8\u05d1\"))))\r\n",
        "Genesis 1:8     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d4\u05d9\"))(P (n \"\u05d1\u05e7\u05e8\"))))\r\n",
        "Genesis 1:8     (S (C (P (p (n \"\u05d9\u05d5\u05dd\"))(p (aj \"\u05e9\u05c1\u05e0\u05d9\")))))\r\n",
        "Genesis 1:9     (S (C (P (cj \"\u05d5\"))(P (vb \"\u05d9\u05d0\u05de\u05e8\"))(P (n \"\u05d0\u05dc\u05d4\u05d9\u05dd\"))))\r\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Anomalies"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* we have suspends and resumes of nodes. Probably to be changed into true embedding.\n",
      "* there are empty words (such as the dt (determiner) in Genesis 1:7.\n",
      "* there are also empty words not attached to non-empty words. These have posed problems in an earlier version of LAF-Fabric,\n",
      "  where node events were not ordered properly.\n",
      "\n",
      "Node events per anchor should be ordered in such a way that closing/suspendig events of non-empty nodes at that anchor come first,\n",
      "followed by events for empty nodes, followed by opening/resuming events."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!grep 'Lamentations 5:3' {my_file('trees.txt')}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Lamentations 5:3 (S (C (P (n \"\u05d9\u05ea\u05d5\u05de\u05d9\u05dd\"))(P (vb \"\u05d4\u05d9\u05d9\u05e0\u05d5\"))))\r\n",
        "Lamentations 5:3 *** (P (cj \"\")) ***\r\n",
        "Lamentations 5:3 (S (C (P (n \"\u05d0\u05d9\u05df\"))(P (n \"\u05d0\u05d1\"))))\r\n",
        "Lamentations 5:3 (S (C (P (n \"\u05d0\u05de\u05ea\u05d9\u05e0\u05d5\"))(P (pp \"\u05db\")(n \"\u05d0\u05dc\u05de\u05e0\u05d5\u05ea\"))))\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!grep 'Judges 20:13' {my_file('trees.txt')}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Judges 20:13    (S (C (P (cj \"\u05d5\"))(P (av \"\u05e2\u05ea\u05d4\"))))\r\n",
        "Judges 20:13    (S (C (P (vb \"\u05ea\u05e0\u05d5\"))(P (pp \"\u05d0\u05ea\")(dt \"\u05d4\")(n \"\u05d0\u05e0\u05e9\u05c1\u05d9\u05dd\")(p (n \"\u05d1\u05e0\u05d9\"))(p (n \"\u05d1\u05dc\u05d9\u05e2\u05dc\"))))(C (P (cj \"\u05d0\u05e9\u05c1\u05e8\"))(P (pp \"\u05d1\")(dt \"\")(n \"\u05d2\u05d1\u05e2\u05d4\"))))\r\n",
        "Judges 20:13    (S (C (P (cj \"\u05d5\"))(P (vb \"\u05e0\u05de\u05d9\u05ea\u05dd\"))))\r\n",
        "Judges 20:13    (S (C (P (cj \"\u05d5\"))(P (vb \"\u05e0\u05d1\u05e2\u05e8\u05d4\"))(P (n \"\u05e8\u05e2\u05d4\"))(P (pp \"\u05de\")(n \"\u05d9\u05e9\u05c2\u05e8\u05d0\u05dc\"))))\r\n",
        "Judges 20:13    (S (C (P (cj \"\u05d5\"))(P (ng \"\u05dc\u05d0\"))(P (vb \"\u05d0\u05d1\u05d5\"))\u00bbP\u00bb\u00bbC\u00bb\u00bbS\u00bb\r\n",
        "Judges 20:13    *** (p (n \"\"))(P  ***\r\n",
        "Judges 20:13    \u00abS\u00ab \u00abC\u00ab \u00abP\u00ab (p (n \"\u05d1\u05e0\u05d9\u05de\u05df\"))))(C (P (pp \"\u05dc\")(vb \"\u05e9\u05c1\u05de\u05e2\"))(P (pp \"\u05d1\")(p (n \"\u05e7\u05d5\u05dc\"))(p (n \"\u05d0\u05d7\u05d9\u05d4\u05dd\"))(p (n \"\u05d1\u05e0\u05d9\"))(p (n \"\u05d9\u05e9\u05c2\u05e8\u05d0\u05dc\")))))\r\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}